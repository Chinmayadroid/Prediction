{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d016ed04-83f6-4f75-959b-f36bd5b20979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing the first dataset...\n",
      "Loading and preprocessing the second dataset...\n",
      "Combining both datasets...\n",
      "Vectorizing the combined cleaned text data...\n",
      "Encoding the target variables...\n",
      "Saving the label encoders...\n",
      "Initializing and training Random Forest for Category...\n",
      "Test Accuracy on Combined Dataset (Category): 0.929384317742119\n",
      "Initializing and training Random Forest for Sub Category...\n",
      "Test Accuracy on Combined Dataset (Sub Category): 0.9670536019119154\n",
      "Saving the models and vectorizer...\n",
      "Models and vectorizer saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "\n",
    "# Function to preprocess data\n",
    "def preprocess_data(data):\n",
    "    data['Purchase Order Text'] = data['Purchase Order Text'].fillna(data['Order Description'])\n",
    "    data['Purchase Order Text'] = data['Purchase Order Text'].astype(str)\n",
    "    data['Order Description'] = data['Order Description'].astype(str)\n",
    "    data['combined_text'] = data['Purchase Order Text'] + ' ' + data['Order Description']\n",
    "    data['cleaned_combined_text'] = data['combined_text'].apply(lambda x: re.sub(r'\\W', ' ', x).lower())\n",
    "    return data\n",
    "\n",
    "# Load and preprocess the first dataset\n",
    "print(\"Loading and preprocessing the first dataset...\")\n",
    "data1 = pd.read_csv(r'C:\\Users\\irt\\Downloads\\all.csv', low_memory=False)\n",
    "data1.dropna(subset=['Purchase Order Text', 'Category', 'Sub Category'], inplace=True)\n",
    "data1 = preprocess_data(data1)\n",
    "\n",
    "# Load and preprocess the second dataset\n",
    "print(\"Loading and preprocessing the second dataset...\")\n",
    "data2 = pd.read_csv(r'C:\\Users\\Public\\Downloads\\TestingData.csv', low_memory=False)\n",
    "data2.dropna(subset=['Purchase Order Text', 'Category', 'Sub Category'], inplace=True)\n",
    "data2 = preprocess_data(data2)\n",
    "\n",
    "# Combine both datasets\n",
    "print(\"Combining both datasets...\")\n",
    "combined_data = pd.concat([data1, data2])\n",
    "\n",
    "# Vectorize the combined cleaned text data\n",
    "print(\"Vectorizing the combined cleaned text data...\")\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_combined = vectorizer.fit_transform(combined_data['cleaned_combined_text'])\n",
    "\n",
    "# Assuming 'Category' and 'Sub Category' are the columns to be predicted\n",
    "y_combined_category = combined_data['Category']\n",
    "y_combined_subcategory = combined_data['Sub Category']\n",
    "\n",
    "# Encode the target variables\n",
    "print(\"Encoding the target variables...\")\n",
    "label_encoder_cat = LabelEncoder()\n",
    "label_encoder_subcat = LabelEncoder()\n",
    "y_combined_category_encoded = label_encoder_cat.fit_transform(y_combined_category)\n",
    "y_combined_subcategory_encoded = label_encoder_subcat.fit_transform(y_combined_subcategory)\n",
    "\n",
    "# Save the label encoders\n",
    "print(\"Saving the label encoders...\")\n",
    "joblib.dump(label_encoder_cat, 'label_encoder_cat.pkl')\n",
    "joblib.dump(label_encoder_subcat, 'label_encoder_subcat.pkl')\n",
    "\n",
    "# Check for classes with only one instance\n",
    "subcategory_counts = Counter(y_combined_subcategory_encoded)\n",
    "rare_subcategories = [subcat for subcat, count in subcategory_counts.items() if count == 1]\n",
    "\n",
    "# Remove instances with rare subcategories\n",
    "if rare_subcategories:\n",
    "    mask = ~combined_data['Sub Category'].isin(label_encoder_subcat.inverse_transform(rare_subcategories))\n",
    "    combined_data = combined_data[mask]\n",
    "    \n",
    "    # Update X_combined and target variables\n",
    "    X_combined = vectorizer.fit_transform(combined_data['cleaned_combined_text'])\n",
    "    y_combined_category_encoded = label_encoder_cat.transform(combined_data['Category'])\n",
    "    y_combined_subcategory_encoded = label_encoder_subcat.transform(combined_data['Sub Category'])\n",
    "\n",
    "# Stratified sampling to get 50% of the data\n",
    "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(\n",
    "    X_combined, y_combined_category_encoded, test_size=0.2, random_state=42, stratify=y_combined_category_encoded)\n",
    "X_train_subcat, X_test_subcat, y_train_subcat, y_test_subcat = train_test_split(\n",
    "    X_combined, y_combined_subcategory_encoded, test_size=0.2, random_state=42, stratify=y_combined_subcategory_encoded)\n",
    "\n",
    "# Initialize and train Random Forest for Category\n",
    "print(\"Initializing and training Random Forest for Category...\")\n",
    "rf_cat = RandomForestClassifier(random_state=42)\n",
    "rf_cat.fit(X_train_cat, y_train_cat)\n",
    "print(f\"Test Accuracy on Combined Dataset (Category): {rf_cat.score(X_test_cat, y_test_cat)}\")\n",
    "\n",
    "# Initialize and train Random Forest for Sub Category\n",
    "print(\"Initializing and training Random Forest for Sub Category...\")\n",
    "rf_subcat = RandomForestClassifier(random_state=42)\n",
    "rf_subcat.fit(X_train_subcat, y_train_subcat)\n",
    "print(f\"Test Accuracy on Combined Dataset (Sub Category): {rf_subcat.score(X_test_subcat, y_test_subcat)}\")\n",
    "\n",
    "# Save the models and vectorizer\n",
    "print(\"Saving the models and vectorizer...\")\n",
    "joblib.dump(rf_cat, 'model_cat_rf.pkl')\n",
    "joblib.dump(rf_subcat, 'model_subcat_rf.pkl')\n",
    "joblib.dump(vectorizer, 'vectorizer_rf.pkl')\n",
    "\n",
    "print(\"Models and vectorizer saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55d3c27b-e686-4de5-8929-6e27f9966351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The following subcategories were unseen and are being mapped to 'unknown': {'Ignore', 'Provisions', nan, 'Water bill'}\n",
      "Category Prediction Accuracy: 89.96%\n",
      "Subcategory Prediction Accuracy: 93.61%\n",
      "Predictions saved to C:\\Users\\Public\\Downloads\\randomforestresult.csv\n",
      "                            Purchase Order Text  \\\n",
      "0                                           nan   \n",
      "1           CHGS.FOR FAB'S WORK JOB IN T2 06/23   \n",
      "2              CHGS.FOR FAB'S WORK JOB IN ELECT   \n",
      "3           CHGS.FOR THERMAL INSU WORK JOB T1 M   \n",
      "4                                           nan   \n",
      "...                                         ...   \n",
      "19995                    FOR PROVISION FY 23-24   \n",
      "19996                                             \n",
      "19997                                             \n",
      "19998                                         0   \n",
      "19999                   FABRICATION WORK INV.99   \n",
      "\n",
      "                               Order Description        Category  \\\n",
      "0                                            nan       R&M - P&M   \n",
      "1            MPP-2 PLANT GENERAL MAINTENANCE JOB  Civil Expenses   \n",
      "2       MCT-1921G Fan & fan hub assembly to be r  Civil Expenses   \n",
      "3                 Scaffholding work Fermentation  Civil Expenses   \n",
      "4                                            nan   House keeping   \n",
      "...                                          ...             ...   \n",
      "19995                     FOR PROVISION FY 23-24       R&M - P&M   \n",
      "19996                     FOR PROVISION FY 23-24       R&M - P&M   \n",
      "19997    Repair & Maint. Bill Prov. For FY 23-24       R&M - P&M   \n",
      "19998  PROV SEP 23-VERTIV ENERGY PRIVATE LIMITED       R&M - P&M   \n",
      "19999                       SS vessel to be weld       R&M - P&M   \n",
      "\n",
      "      Predicted Category Category Match      Sub Category  \\\n",
      "0              R&M - P&M            Yes           unknown   \n",
      "1         Civil Expenses            Yes  Other civil work   \n",
      "2         Civil Expenses            Yes  Other civil work   \n",
      "3              R&M - P&M             No       Scaffolding   \n",
      "4              R&M - P&M             No      Housekeeping   \n",
      "...                  ...            ...               ...   \n",
      "19995          R&M - P&M            Yes         Provision   \n",
      "19996          R&M - P&M            Yes         Provision   \n",
      "19997     Civil Expenses             No         Provision   \n",
      "19998          R&M - P&M            Yes         Other R&M   \n",
      "19999          R&M - P&M            Yes         Other R&M   \n",
      "\n",
      "      Predicted Sub Category Subcategory Match  \n",
      "0             Transfer to IO                No  \n",
      "1           Other civil work               Yes  \n",
      "2           Other civil work               Yes  \n",
      "3                Scaffolding               Yes  \n",
      "4             Transfer to IO                No  \n",
      "...                      ...               ...  \n",
      "19995              Provision               Yes  \n",
      "19996              Provision               Yes  \n",
      "19997              Provision               Yes  \n",
      "19998              Other R&M               Yes  \n",
      "19999              Other R&M               Yes  \n",
      "\n",
      "[20000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to preprocess data\n",
    "def preprocess_data(data):\n",
    "    data['Purchase Order Text'] = data['Purchase Order Text'].fillna(data['Order Description'])\n",
    "    data['Purchase Order Text'] = data['Purchase Order Text'].astype(str)\n",
    "    data['Order Description'] = data['Order Description'].astype(str)\n",
    "    data['combined_text'] = data['Purchase Order Text'] + ' ' + data['Order Description']\n",
    "    data['cleaned_combined_text'] = data['combined_text'].apply(lambda x: re.sub(r'\\W', ' ', x).lower())\n",
    "    return data\n",
    "\n",
    "# Function to load the CSV file with different encodings\n",
    "def load_csv_file(file_path):\n",
    "    encodings = ['utf-8', 'latin1', 'iso-8859-1', 'cp1252']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            return pd.read_csv(file_path, encoding=encoding, low_memory=False)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise ValueError(\"Unable to read the CSV file with the specified encodings.\")\n",
    "\n",
    "# Load the saved models and vectorizer\n",
    "vectorizer = joblib.load('vectorizer_rf.pkl')\n",
    "model_cat = joblib.load('model_cat_rf.pkl')\n",
    "model_subcat = joblib.load('model_subcat_rf.pkl')\n",
    "label_encoder_cat = joblib.load('label_encoder_cat.pkl')\n",
    "label_encoder_subcat = joblib.load('label_encoder_subcat.pkl')\n",
    "\n",
    "# Define the path to your CSV file\n",
    "input_file_path = r'C:\\Users\\Public\\Downloads\\finallynew.csv'  # Update this to the actual path of your input CSV file\n",
    "\n",
    "# Load the new input CSV file\n",
    "input_data = load_csv_file(input_file_path)\n",
    "\n",
    "# Preprocess the input data\n",
    "preprocessed_input_data = preprocess_data(input_data)\n",
    "\n",
    "# Vectorize the cleaned combined text data\n",
    "vectorized_input_data = vectorizer.transform(preprocessed_input_data['cleaned_combined_text'])\n",
    "\n",
    "# Make predictions for each row\n",
    "category_predictions = model_cat.predict(vectorized_input_data)\n",
    "subcategory_predictions = model_subcat.predict(vectorized_input_data)\n",
    "\n",
    "# Decode the predictions\n",
    "decoded_category_predictions = label_encoder_cat.inverse_transform(category_predictions)\n",
    "decoded_subcategory_predictions = label_encoder_subcat.inverse_transform(subcategory_predictions)\n",
    "\n",
    "# Display the predictions\n",
    "input_data['Predicted Category'] = decoded_category_predictions\n",
    "input_data['Predicted Sub Category'] = decoded_subcategory_predictions\n",
    "\n",
    "# Handle unseen labels for subcategories by mapping them to a default value or ignoring them\n",
    "unseen_labels_subcat = set(input_data['Sub Category']) - set(label_encoder_subcat.classes_)\n",
    "if unseen_labels_subcat:\n",
    "    print(f\"Warning: The following subcategories were unseen and are being mapped to 'unknown': {unseen_labels_subcat}\")\n",
    "    input_data['Sub Category'] = input_data['Sub Category'].apply(lambda x: 'unknown' if x in unseen_labels_subcat else x)\n",
    "\n",
    "# If actual labels are available in the input data, create match columns\n",
    "if 'Category' in input_data.columns and 'Sub Category' in input_data.columns:\n",
    "    input_data['Category Match'] = np.where(input_data['Category'] == input_data['Predicted Category'], 'Yes', 'No')\n",
    "    input_data['Subcategory Match'] = np.where(input_data['Sub Category'] == input_data['Predicted Sub Category'], 'Yes', 'No')\n",
    "\n",
    "    # Calculate accuracy if actual labels are present\n",
    "    try:\n",
    "        # Filter out rows with 'unknown' labels before calculating accuracy\n",
    "        filtered_data = input_data[(input_data['Sub Category'] != 'unknown') & (input_data['Predicted Sub Category'] != 'unknown')]\n",
    "\n",
    "        if not filtered_data.empty:\n",
    "            actual_category = label_encoder_cat.transform(filtered_data['Category'])\n",
    "            actual_subcategory = label_encoder_subcat.transform(filtered_data['Sub Category'])\n",
    "\n",
    "            filtered_category_predictions = label_encoder_cat.transform(filtered_data['Predicted Category'])\n",
    "            filtered_subcategory_predictions = label_encoder_subcat.transform(filtered_data['Predicted Sub Category'])\n",
    "\n",
    "            category_accuracy = accuracy_score(actual_category, filtered_category_predictions)\n",
    "            subcategory_accuracy = accuracy_score(actual_subcategory, filtered_subcategory_predictions)\n",
    "\n",
    "            print(f'Category Prediction Accuracy: {category_accuracy * 100:.2f}%')\n",
    "            print(f'Subcategory Prediction Accuracy: {subcategory_accuracy * 100:.2f}%')\n",
    "        else:\n",
    "            print(\"No valid data available for accuracy calculation after filtering out 'unknown' labels.\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in accuracy calculation: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"Columns 'Category' and 'Sub Category' not found in input_data.\")\n",
    "\n",
    "# Save the prediction results to a new CSV file\n",
    "output_file_path = r'C:\\Users\\Public\\Downloads\\randomforestresult.csv'\n",
    "input_data.to_csv(output_file_path, index=False)\n",
    "print(f\"Predictions saved to {output_file_path}\")\n",
    "\n",
    "# Display the predictions\n",
    "print(input_data[['Purchase Order Text', 'Order Description', 'Category', 'Predicted Category', 'Category Match', 'Sub Category', 'Predicted Sub Category', 'Subcategory Match']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd52962-6625-48ab-b0b5-76b4cb0f87f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99143a5-d480-4f1d-8e8a-e24c85a976d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

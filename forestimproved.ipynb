{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85ccf7be-8641-4f8a-a71b-b52e55977a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing C:\\Users\\irt\\Downloads\\all.csv...\n",
      "Loading and preprocessing C:\\Users\\Public\\Downloads\\TestingData.csv...\n",
      "Combining both datasets...\n",
      "Vectorizing the combined cleaned text data...\n",
      "Encoding the target variables...\n",
      "Saving the label encoders...\n",
      "Initializing and training Random Forest for Category with GridSearchCV...\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Best parameters for category: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Test Accuracy on Combined Dataset (Category): 0.9281893706612041\n",
      "Initializing and training Random Forest for Sub Category with GridSearchCV...\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irt\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for subcategory: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Test Accuracy on Combined Dataset (Sub Category): 0.965631045863207\n",
      "Saving the models and vectorizer...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "\n",
    "# Function to preprocess data\n",
    "def preprocess_data(data):\n",
    "    data['Purchase Order Text'] = data['Purchase Order Text'].fillna(data['Order Description'])\n",
    "    data['Purchase Order Text'] = data['Purchase Order Text'].astype(str)\n",
    "    data['Order Description'] = data['Order Description'].astype(str)\n",
    "    data['combined_text'] = data['Purchase Order Text'] + ' ' + data['Order Description']\n",
    "    data['cleaned_combined_text'] = data['combined_text'].apply(lambda x: re.sub(r'\\W', ' ', x).lower().strip())\n",
    "    return data\n",
    "\n",
    "# Function to load the CSV file with different encodings\n",
    "def load_csv_file(file_path):\n",
    "    encodings = ['utf-8', 'latin1', 'iso-8859-1', 'cp1252']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            return pd.read_csv(file_path, encoding=encoding, low_memory=False)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise ValueError(\"Unable to read the CSV file with the specified encodings.\")\n",
    "\n",
    "# Function to load and preprocess the datasets\n",
    "def load_and_preprocess(file_path):\n",
    "    print(f\"Loading and preprocessing {file_path}...\")\n",
    "    data = load_csv_file(file_path)\n",
    "    data.dropna(subset=['Purchase Order Text', 'Category', 'Sub Category'], inplace=True)\n",
    "    return preprocess_data(data)\n",
    "\n",
    "# Function to train the models\n",
    "def train_models(train_file_paths):\n",
    "    # Load and preprocess the datasets\n",
    "    data1 = load_and_preprocess(train_file_paths[0])\n",
    "    data2 = load_and_preprocess(train_file_paths[1])\n",
    "\n",
    "    # Combine both datasets\n",
    "    print(\"Combining both datasets...\")\n",
    "    combined_data = pd.concat([data1, data2])\n",
    "\n",
    "    # Vectorize the combined cleaned text data\n",
    "    print(\"Vectorizing the combined cleaned text data...\")\n",
    "    vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')\n",
    "    X_combined = vectorizer.fit_transform(combined_data['cleaned_combined_text'])\n",
    "\n",
    "    # Encode the target variables\n",
    "    print(\"Encoding the target variables...\")\n",
    "    label_encoder_cat = LabelEncoder()\n",
    "    label_encoder_subcat = LabelEncoder()\n",
    "    y_combined_category_encoded = label_encoder_cat.fit_transform(combined_data['Category'])\n",
    "    y_combined_subcategory_encoded = label_encoder_subcat.fit_transform(combined_data['Sub Category'])\n",
    "\n",
    "    # Save the label encoders\n",
    "    print(\"Saving the label encoders...\")\n",
    "    joblib.dump(label_encoder_cat, 'label_encoder_cat.pkl')\n",
    "    joblib.dump(label_encoder_subcat, 'label_encoder_subcat.pkl')\n",
    "\n",
    "    # Handle rare subcategories\n",
    "    subcategory_counts = Counter(y_combined_subcategory_encoded)\n",
    "    rare_subcategories = [subcat for subcat, count in subcategory_counts.items() if count == 1]\n",
    "    if rare_subcategories:\n",
    "        mask = ~combined_data['Sub Category'].isin(label_encoder_subcat.inverse_transform(rare_subcategories))\n",
    "        combined_data = combined_data[mask]\n",
    "        X_combined = vectorizer.fit_transform(combined_data['cleaned_combined_text'])\n",
    "        y_combined_category_encoded = label_encoder_cat.transform(combined_data['Category'])\n",
    "        y_combined_subcategory_encoded = label_encoder_subcat.transform(combined_data['Sub Category'])\n",
    "\n",
    "    # Stratified sampling to split the data\n",
    "    X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(\n",
    "        X_combined, y_combined_category_encoded, test_size=0.2, random_state=42, stratify=y_combined_category_encoded)\n",
    "    X_train_subcat, X_test_subcat, y_train_subcat, y_test_subcat = train_test_split(\n",
    "        X_combined, y_combined_subcategory_encoded, test_size=0.2, random_state=42, stratify=y_combined_subcategory_encoded)\n",
    "\n",
    "    # Initialize and train Random Forest with GridSearchCV\n",
    "    print(\"Initializing and training Random Forest for Category with GridSearchCV...\")\n",
    "    rf_cat = RandomForestClassifier(random_state=42)\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5]\n",
    "    }\n",
    "    grid_cat = GridSearchCV(rf_cat, param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "    grid_cat.fit(X_train_cat, y_train_cat)\n",
    "    print(f\"Best parameters for category: {grid_cat.best_params_}\")\n",
    "    print(f\"Test Accuracy on Combined Dataset (Category): {grid_cat.score(X_test_cat, y_test_cat)}\")\n",
    "\n",
    "    print(\"Initializing and training Random Forest for Sub Category with GridSearchCV...\")\n",
    "    rf_subcat = RandomForestClassifier(random_state=42)\n",
    "    grid_subcat = GridSearchCV(rf_subcat, param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "    grid_subcat.fit(X_train_subcat, y_train_subcat)\n",
    "    print(f\"Best parameters for subcategory: {grid_subcat.best_params_}\")\n",
    "    print(f\"Test Accuracy on Combined Dataset (Sub Category): {grid_subcat.score(X_test_subcat, y_test_subcat)}\")\n",
    "\n",
    "    # Save the models and vectorizer\n",
    "    print(\"Saving the models and vectorizer...\")\n",
    "    joblib.dump(grid_cat.best_estimator_, 'model_cat_rf.pkl')\n",
    "    joblib.dump(grid_subcat.best_estimator_, 'model_subcat_rf.pkl')\n",
    "    joblib.dump(vectorizer, 'vectorizer_rf.pkl')\n",
    "\n",
    "# Paths to your training datasets\n",
    "train_file_paths = [\n",
    "    r'C:\\Users\\irt\\Downloads\\all.csv',\n",
    "    r'C:\\Users\\Public\\Downloads\\TestingData.csv'\n",
    "]\n",
    "\n",
    "# Run the training function\n",
    "train_models(train_file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9c77b62-1da0-4497-8cd0-8f88512f9cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unseen subcategories being mapped to 'unknown': {'Provisions', 'Water bill', nan, 'Ignore'}\n",
      "Category Prediction Accuracy: 89.36%\n",
      "Subcategory Prediction Accuracy: 92.81%\n",
      "Predictions saved to C:\\Users\\Public\\Downloads\\forestimporvedlatestresultlong.csv\n",
      "                            Purchase Order Text  \\\n",
      "0                                           nan   \n",
      "1           CHGS.FOR FAB'S WORK JOB IN T2 06/23   \n",
      "2              CHGS.FOR FAB'S WORK JOB IN ELECT   \n",
      "3           CHGS.FOR THERMAL INSU WORK JOB T1 M   \n",
      "4                                           nan   \n",
      "...                                         ...   \n",
      "19995                    FOR PROVISION FY 23-24   \n",
      "19996                                             \n",
      "19997                                             \n",
      "19998                                         0   \n",
      "19999                   FABRICATION WORK INV.99   \n",
      "\n",
      "                               Order Description        Category  \\\n",
      "0                                            nan       R&M - P&M   \n",
      "1            MPP-2 PLANT GENERAL MAINTENANCE JOB  Civil Expenses   \n",
      "2       MCT-1921G Fan & fan hub assembly to be r  Civil Expenses   \n",
      "3                 Scaffholding work Fermentation  Civil Expenses   \n",
      "4                                            nan   House keeping   \n",
      "...                                          ...             ...   \n",
      "19995                     FOR PROVISION FY 23-24       R&M - P&M   \n",
      "19996                     FOR PROVISION FY 23-24       R&M - P&M   \n",
      "19997    Repair & Maint. Bill Prov. For FY 23-24       R&M - P&M   \n",
      "19998  PROV SEP 23-VERTIV ENERGY PRIVATE LIMITED       R&M - P&M   \n",
      "19999                       SS vessel to be weld       R&M - P&M   \n",
      "\n",
      "      Predicted Category Category Match      Sub Category  \\\n",
      "0              R&M - P&M            Yes           unknown   \n",
      "1         Civil Expenses            Yes  Other civil work   \n",
      "2         Civil Expenses            Yes  Other civil work   \n",
      "3              R&M - P&M             No       Scaffolding   \n",
      "4              R&M - P&M             No      Housekeeping   \n",
      "...                  ...            ...               ...   \n",
      "19995          R&M - P&M            Yes         Provision   \n",
      "19996          R&M - P&M            Yes         Provision   \n",
      "19997     Civil Expenses             No         Provision   \n",
      "19998          R&M - P&M            Yes         Other R&M   \n",
      "19999          R&M - P&M            Yes         Other R&M   \n",
      "\n",
      "      Predicted Sub Category Subcategory Match  \n",
      "0                  Other R&M                No  \n",
      "1           Other civil work               Yes  \n",
      "2           Other civil work               Yes  \n",
      "3                Scaffolding               Yes  \n",
      "4                  Other R&M                No  \n",
      "...                      ...               ...  \n",
      "19995              Provision               Yes  \n",
      "19996              Provision               Yes  \n",
      "19997              Provision               Yes  \n",
      "19998              Other R&M               Yes  \n",
      "19999              Other R&M               Yes  \n",
      "\n",
      "[20000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Function to preprocess data\n",
    "def preprocess_data(data):\n",
    "    data['Purchase Order Text'] = data['Purchase Order Text'].fillna(data['Order Description'])\n",
    "    data['Purchase Order Text'] = data['Purchase Order Text'].astype(str)\n",
    "    data['Order Description'] = data['Order Description'].astype(str)\n",
    "    data['combined_text'] = data['Purchase Order Text'] + ' ' + data['Order Description']\n",
    "    data['cleaned_combined_text'] = data['combined_text'].apply(lambda x: re.sub(r'\\W', ' ', x).lower().strip())\n",
    "    return data\n",
    "\n",
    "# Function to load the CSV file with different encodings\n",
    "def load_csv_file(file_path):\n",
    "    encodings = ['utf-8', 'latin1', 'iso-8859-1', 'cp1252']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            return pd.read_csv(file_path, encoding=encoding, low_memory=False)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise ValueError(\"Unable to read the CSV file with the specified encodings.\")\n",
    "\n",
    "# Function to test and predict with the trained models\n",
    "def test_and_predict(input_file_path):\n",
    "    # Load and preprocess new input data for prediction\n",
    "    input_data = load_csv_file(input_file_path)\n",
    "    input_data = preprocess_data(input_data)\n",
    "\n",
    "    # Load the saved models and vectorizer\n",
    "    vectorizer = joblib.load('vectorizer_rf.pkl')\n",
    "    model_cat = joblib.load('model_cat_rf.pkl')\n",
    "    model_subcat = joblib.load('model_subcat_rf.pkl')\n",
    "    label_encoder_cat = joblib.load('label_encoder_cat.pkl')\n",
    "    label_encoder_subcat = joblib.load('label_encoder_subcat.pkl')\n",
    "\n",
    "    # Vectorize and predict new input data\n",
    "    vectorized_input_data = vectorizer.transform(input_data['cleaned_combined_text'])\n",
    "    category_predictions = model_cat.predict(vectorized_input_data)\n",
    "    subcategory_predictions = model_subcat.predict(vectorized_input_data)\n",
    "\n",
    "    # Decode predictions\n",
    "    input_data['Predicted Category'] = label_encoder_cat.inverse_transform(category_predictions)\n",
    "    input_data['Predicted Sub Category'] = label_encoder_subcat.inverse_transform(subcategory_predictions)\n",
    "\n",
    "    # Handle unseen labels\n",
    "    unseen_labels_subcat = set(input_data['Sub Category']) - set(label_encoder_subcat.classes_)\n",
    "    if unseen_labels_subcat:\n",
    "        print(f\"Warning: Unseen subcategories being mapped to 'unknown': {unseen_labels_subcat}\")\n",
    "        input_data['Sub Category'] = input_data['Sub Category'].apply(lambda x: 'unknown' if x in unseen_labels_subcat else x)\n",
    "\n",
    "    # Check accuracy if actual labels exist\n",
    "    if 'Category' in input_data.columns and 'Sub Category' in input_data.columns:\n",
    "        input_data['Category Match'] = np.where(input_data['Category'] == input_data['Predicted Category'], 'Yes', 'No')\n",
    "        input_data['Subcategory Match'] = np.where(input_data['Sub Category'] == input_data['Predicted Sub Category'], 'Yes', 'No')\n",
    "        filtered_data = input_data[(input_data['Sub Category'] != 'unknown') & (input_data['Predicted Sub Category'] != 'unknown')]\n",
    "\n",
    "        if not filtered_data.empty:\n",
    "            actual_category = label_encoder_cat.transform(filtered_data['Category'])\n",
    "            actual_subcategory = label_encoder_subcat.transform(filtered_data['Sub Category'])\n",
    "            filtered_category_predictions = label_encoder_cat.transform(filtered_data['Predicted Category'])\n",
    "            filtered_subcategory_predictions = label_encoder_subcat.transform(filtered_data['Predicted Sub Category'])\n",
    "\n",
    "            category_accuracy = accuracy_score(actual_category, filtered_category_predictions)\n",
    "            subcategory_accuracy = accuracy_score(actual_subcategory, filtered_subcategory_predictions)\n",
    "\n",
    "            print(f'Category Prediction Accuracy: {category_accuracy * 100:.2f}%')\n",
    "            print(f'Subcategory Prediction Accuracy: {subcategory_accuracy * 100:.2f}%')\n",
    "        else:\n",
    "            print(\"No valid data available for accuracy calculation after filtering out 'unknown' labels.\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    output_file_path = r'C:\\Users\\Public\\Downloads\\forestimporvedlatestresultlong.csv'\n",
    "    input_data.to_csv(output_file_path, index=False)\n",
    "    print(f\"Predictions saved to {output_file_path}\")\n",
    "\n",
    "    print(input_data[['Purchase Order Text', 'Order Description', 'Category', 'Predicted Category', 'Category Match', 'Sub Category', 'Predicted Sub Category', 'Subcategory Match']])\n",
    "\n",
    "# Path to your testing dataset\n",
    "input_file_path = r'C:\\Users\\Public\\Downloads\\finallynew.csv'\n",
    "\n",
    "# Run the testing and prediction function\n",
    "test_and_predict(input_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
